# Procesador de Documentos en Google Cloud

Este proyecto implementa un sistema de procesamiento autom√°tico de documentos en Google Cloud, utilizando Cloud Functions para manejar eventos de almacenamiento, Document AI para extracci√≥n de texto, OpenAI para an√°lisis de contenido y generaci√≥n de embeddings, y Redis como base de datos vectorial y de metadatos.

## Caracter√≠sticas Principales

- üîÑ **Procesamiento autom√°tico de documentos** cuando se suben a Cloud Storage
- üîç **Extracci√≥n de texto mediante OCR** utilizando Document AI
- üß† **An√°lisis de contenido con OpenAI** para identificar t√≥picos y generar preguntas frecuentes
- üî¢ **Indexaci√≥n y b√∫squeda vectorial con Redis Vector Search** para b√∫squeda sem√°ntica de alta precisi√≥n
- üíæ **Almacenamiento estructurado** de metadatos, t√≥picos y preguntas en Redis
- üèóÔ∏è **Arquitectura modular** siguiendo principios de programaci√≥n funcional

## üìÅ Estructura del Proyecto
```
src/
‚îú‚îÄ‚îÄ main.py                # Punto de entrada 
‚îú‚îÄ‚îÄ config.py              # Configuraci√≥n y variables de entorno
‚îú‚îÄ‚îÄ document_handlers.py   # Manejadores para diferentes eventos de documentos
‚îú‚îÄ‚îÄ content_processor.py   # Procesamiento del contenido de documentos
‚îú‚îÄ‚îÄ ai_services.py         # Servicios de IA (Gemini, embeddings)
‚îú‚îÄ‚îÄ storage_service.py     # Operaciones con Cloud Storage
‚îú‚îÄ‚îÄ database_service.py    # Operaciones con Redis
‚îî‚îÄ‚îÄ vector_search.py       # Operaciones con Vector Search en Redis
```

### üìã Descripci√≥n de M√≥dulos

- üéØ **main.py**: Contiene la funci√≥n principal `on_cloud_event` que procesa eventos de Cloud Storage y orquesta el flujo de trabajo.
- ‚öôÔ∏è **config.py**: Centraliza todas las variables de entorno y configuraciones del sistema. Mantiene la conexi√≥n de Redis compartida.
- üìù **document_handlers.py**: Maneja los diferentes tipos de eventos (creaci√≥n, actualizaci√≥n, eliminaci√≥n) de documentos.
- üìÑ **content_processor.py**: Implementa la extracci√≥n de texto de documentos usando Document AI.
- ü§ñ **ai_service.py**: Proporciona funciones para extraer t√≥picos, generar preguntas y crear embeddings utilizando OpenAI.
- üóÇÔ∏è **storage_service.py**: Maneja operaciones con Cloud Storage como obtener metadatos de archivos.
- üóÉÔ∏è **database_service.py**: Gestiona operaciones CRUD con Redis para almacenar y recuperar metadatos, t√≥picos y preguntas.
- üîç **vector_search.py**: Implementa funciones para indexar y buscar embeddings en Redis Vector Search.

## üîß Requisitos

- Google Cloud Project con las siguientes APIs habilitadas:
  - Cloud Functions
  - Cloud Storage
  - Document AI
- API Key de OpenAI
- Procesador de Document AI configurado
- Redis Stack con Redis Vector Search habilitado
  - Se requiere Redis Stack 7.2.0 o superior
  - Compatible con Redis Cloud o implementaci√≥n local/self-hosted
  - Capacidad para indexar vectores de alta dimensionalidad (1536D)
- Permisos adecuados para la cuenta de servicio

## Variables de Entorno

La funci√≥n requiere las siguientes variables de entorno:

| Variable | Descripci√≥n |
|----------|-------------|
| `DOCAI_LOCATION` | Ubicaci√≥n de Document AI (default: "us") |
| `REDIS_URL` | URL de conexi√≥n a Redis (default: "redis://localhost:6379") |
| `OUTPUT_BUCKET` | Bucket para almacenar resultados temporales |
| `INDEX_ID` | ID del √≠ndice de Vector Search en Redis |
| `DOCAI_PROCESSOR` | ID completo del procesador de Document AI |
| `OPENAI_API_KEY` | API Key de OpenAI |
| `OPENAI_MODEL` | Modelo de OpenAI a utilizar (default: "gpt-4.1") |

## Configuraci√≥n de Redis Vector Search

El sistema utiliza la biblioteca `redisvl` para crear y gestionar √≠ndices vectoriales en Redis:

```python
# Ejemplo de configuraci√≥n del √≠ndice vectorial
{
    "index": {
        "name": "index_name",         # Nombre del √≠ndice definido en INDEX_ID
        "prefix": "docs",             # Prefijo para las claves en Redis
    },
    "fields": [
        {"name": "filename", "type": "tag"},               # Etiqueta para b√∫squeda exacta
        {"name": "page", "type": "numeric"},               # Campo num√©rico para paginaci√≥n
        {"name": "content", "type": "text"},               # Texto completo para b√∫squeda fulltext
        {
            "name": "embedding",
            "type": "vector",
            "attrs": {
                "dims": 1536,                              # Dimensiones para embeddings de OpenAI
                "distance_metric": "cosine",               # M√©trica de distancia
                "algorithm": "flat",                       # Algoritmo de b√∫squeda
                "datatype": "float32",                     # Tipo de datos
            },
        },
    ],
}
```

Los par√°metros importantes a considerar para la implementaci√≥n son:

1. **Dimensiones**: Configurado a 1536 para compatibilidad con `text-embedding-3-small` de OpenAI
2. **Distancia**: Utiliza la m√©trica de similitud del coseno para resultados m√°s precisos
3. **Algoritmo**: Implementa FLAT para b√∫squeda exhaustiva (mejor precisi√≥n)
4. **Prefijo**: Todas las claves en Redis usan el prefijo "docs:" para el √≠ndice vectorial

## Implementaci√≥n de Redis Vector Search

El sistema utiliza Redis no solo como base de datos para almacenar metadatos, sino tambi√©n como motor de b√∫squeda vectorial mediante Redis Vector Search.

### Caracter√≠sticas de Redis Vector Search

- **Indexaci√≥n eficiente**: Almacena embeddings como vectores de 1536 dimensiones (formato OpenAI text-embedding-3-small)
- **B√∫squeda por similitud**: Permite buscar contenido sem√°nticamente similar usando la distancia coseno
- **Algoritmo FLAT**: Implementa el algoritmo FLAT para una b√∫squeda vectorial precisa
- **Campos estructurados**: Cada entrada indexada contiene:
  - `filename`: Identificador del documento (campo tag)
  - `page`: N√∫mero de p√°gina (campo num√©rico)
  - `content`: Texto completo de la p√°gina (campo texto)
  - `embedding`: Vector de embedding (campo vector)

### Esquema de Datos en Redis

```
# Documentos
document:{filename} -> JSON con metadatos del documento

# T√≥picos y preguntas
topics:{filename} -> JSON con t√≥picos extra√≠dos
questions:{filename} -> JSON con preguntas generadas

# Vector Search (prefijo "docs")
docs:{uuid} -> Hash con campos {filename, page, content, embedding}
```

## Flujo de Trabajo

### Creaci√≥n o Actualizaci√≥n de Documentos

1. Se sube un documento a Cloud Storage o se actualiza sus metadatos
2. Se activa la Cloud Function mediante un evento de Cloud Storage
3. Se extraen metadatos del documento y se guardan en Redis
4. Se procesa el documento con Document AI para extraer texto
5. Se utiliza OpenAI para extraer t√≥picos y generar preguntas frecuentes
6. Se almacenan los t√≥picos y preguntas en Redis
7. Se crean embeddings para cada p√°gina del documento usando OpenAI text-embedding-3-small
8. Se indexan los embeddings en Redis Vector Search para b√∫squeda sem√°ntica

### Eliminaci√≥n de Documentos

1. Se elimina un documento de Cloud Storage
2. Se activa la Cloud Function mediante un evento de eliminaci√≥n
3. Se eliminan las referencias al documento en Redis
4. Se eliminan los datapoints correspondientes del √≠ndice de Vector Search

## Operaciones Principales con Redis Vector Search

El m√≥dulo `vector_search.py` proporciona las siguientes operaciones principales:

### Indexaci√≥n de Contenido

```python
# Indexar p√°ginas de un documento
index_pages(index_name, filename, pages, embeddings)
```

Este proceso:
1. Crea el √≠ndice si no existe
2. Genera un documento para cada p√°gina con su texto y embedding
3. Carga los documentos en el √≠ndice Redis Vector Search


### Eliminaci√≥n de Documentos

```python
# Eliminar todos los datapoints de un documento
remove_datapoints(index_name, filename, page_count)
```

Este proceso:
1. Busca todas las claves en Redis con el prefijo del √≠ndice
2. Filtra las que corresponden al filename especificado
3. Elimina las claves encontradas

